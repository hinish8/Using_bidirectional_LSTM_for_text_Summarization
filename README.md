# Bidirectional LSTM: Abstract Text Summarization
![](http://abigailsee.com/img/pointer-gen.png)

## Introduction
This project involves the development of a text summarization model using bidirectional LSTM to create clear and concise summaries. The model aims to generate human-like summaries by capturing the essence of the input text.

### Project Summary
- Development: Created a text summarization model using bidirectional LSTM to produce coherent summaries.
- Text Preprocessing: Implemented text preprocessing techniques and used GloVe embeddings for enhanced word representation.
- Model Design: Designed and trained an encoder-decoder model with bidirectional LSTM to understand context from both directions.
- Evaluation: Evaluated the modelâ€™s performance using accuracy and loss metrics.
- Visualization: Visualized results with Matplotlib.
- Model Saving: Saved the model for future use and deployment.
- Future Work: Currently exploring GPT-4 to improve summary evaluations.
- Outcome: Successfully generated accurate and meaningful summaries.

### Summarization Types
Summarization can be broadly classified into two types:

- Extractive Summarization: This method selects sentences directly from the source text to form a summary.
- Abstractive Summarization: This method generates new sentences that convey the main ideas of the source text, resulting in more natural and human-like summaries.

- Chosen Approach
Abstractive Summarization: Opted for this approach to produce summaries that are more fluent and better capture the essence of the original text.



## Reference

-[Basics to text Summarization]( https://medium.com/analytics-vidhya/text-summarization-using-nlp-3e85ad0c6349)
-[Metrics for evaluating summarization of text performed by transformers](https://fabianofalcao.medium.com/metrics-for-evaluating-summarization-of-texts-performed-by-transformers-how-to-evaluate-the-b3ce68a309c3)
-[Why summarizing is so difficult in NLP?](https://www.abstractivehealth.com/article/why-is-summarizing-so-difficult-in-nlp)
-[Why Bidirectional LSTM was used?](https://arxiv.org/pdf/1809.06662)


- [Get To The Point: Summarization with Pointer-Generator Networks](https://nlp.stanford.edu/pubs/see2017get.pdf)
- [Bidirectional Attentional Encoder-Decoder Model and Bidirectional Beam Search for Abstractive Summarization](https://arxiv.org/pdf/1809.06662.pdf)
- [Taming Recurrent Neural Networks for Better Summarization](http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html)
- [Encoder-Decoder Models for Text Summarization in Keras](https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/)
- [Text Summarization Using Keras Models](https://hackernoon.com/text-summarization-using-keras-models-366b002408d9)
- [Text Summarization in Python: Extractive vs. Abstractive techniques revisited](https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/)
- 
